#@package _global_

defaults:
  - /data: pastis_subpatched
  - /model: prithvi_segmentation
  - override /plugins: mixed_precision

experiment_name: &val_experiment_name "finetuning-prithvi-segmentation"
tags: &val_tags ["prithvi-segmentation", "finetunning"]

_indices: &var_data_transform_indices [0, 1, 2, 7, 8, 9]
_shape: &var_data_transform_shape [-1, 128, 128]
_num_frames: &var_num_frames 3
_num_classes: &var_num_classes 20
_monitor_metric: &var_monitor_metric "val/accuracy"

callbacks:
  model_checkpoint:
    monitor: *var_monitor_metric
    mode: "max"
  early_stopping:
    monitor: *var_monitor_metric
    mode: "max"
    patience: 60

logger:
  mlflow:
    experiment_name: *val_experiment_name
    tags: [*val_tags]

data:
  train:
    subpatch_size: *var_num_frames
    transforms:
      - _target_: src.data.transforms.FromNumpy
      - _target_: torchvision.transforms.Normalize
        _partial_: True
      - _target_: src.data.transforms.Transpose
        dim0: 0
        dim1: 1
      - _target_: src.data.transforms.Take
        indices: *var_data_transform_indices
        dim: 0
    shared_transforms:
      - _target_: src.data.transforms.MultiStepRandomTransform
        steps: 2
        callback:
          _target_: src.data.functional.vflip
          _partial_: True
      - _target_: src.data.transforms.MultiStepRandomTransform
        steps: 2
        callback:
          _target_: src.data.functional.hflip
          _partial_: True
  val:
    subpatch_size: *var_num_frames
    transforms:
      - _target_: src.data.transforms.FromNumpy
      - _target_: torchvision.transforms.Normalize
        _partial_: True
      - _target_: src.data.transforms.Transpose
        dim0: 0
        dim1: 1
      - _target_: src.data.transforms.Take
        indices: *var_data_transform_indices
        dim: 0
  test:
    subpatch_size: *var_num_frames
    transforms:
      - _target_: src.data.transforms.FromNumpy
      - _target_: torchvision.transforms.Normalize
        _partial_: True
      - _target_: src.data.transforms.Transpose
        dim0: 0
        dim1: 1
      - _target_: src.data.transforms.Take
        indices: *var_data_transform_indices
        dim: 0

model:
  net:
    img_size: 128
    num_classes: *var_num_classes
    num_frames: *var_num_frames
    decoder: "UTRSegDecoder"
    weights: "none"
  criterion:
    _target_: torch.nn.CrossEntropyLoss
    _partial_: True
    #_target_: src.models.components.losses.dice_loss.DiceLoss
    #mode: multiclass
    #ignore_index: 0
    #from_logits: True
    #log_loss: True
    #label_smoothing: 0.1
  optimizer:
    _target_: torch.optim.Adam
    lr: 5e-4
    #weight_decay: 1e-5 # L2 regularization
  scheduler:
    _target_: torch.optim.lr_scheduler.StepLR
    _partial_: True
    step_size: 6
    gamma: 0.5
  class_weight_strategy: "per-batch"
  optimizer_strategy:
    strategy: "backbone-lr"
    backbone_lr: 1e-6
    end: 30

trainer:
  max_epochs: 200
  gradient_clip_val: 0.1
    